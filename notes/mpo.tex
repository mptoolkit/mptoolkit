% notes on triangular MPO's
% $Id$
\documentclass{article}[10pt]
\input{macros}
\begin{document}

\title{Solving Triangular MPO's}

\author{I. P. McCulloch}
\date{\today}

\maketitle

\section{Introduction}

These notes are a first draft at a classification of triangular MPO's. 
These describe operators that are polynomial functions of sums of local operators.
The simplest example is the $W$-like operator, of the sum of local terms
at every site,
\begin{equation}
X_{tot} = \sum_i X_i \; .
\end{equation}
This has the MPO form
\begin{equation}
W_{X_{tot}} = \left( \begin{array}{cc} I & 0 \\ X & I \end{array} \right) \; .
\end{equation}

For each index of the $M \times M$ dimensional 
MPO, there is an associated $E$ matrix (in DMRG notation,
this is called the \emph{block operator}).
To find the expectation value of these operators, we can use a recursive formula
based on the notion that the operators $E_i$ are a function only of the
previously calculated $E_j$, for $j > i$. This means that we can find the 
expectation value in time $O(m^3 d M^2)$, which is surely the most efficient
bound for a generic triangular MPO.

\section{Evaluating the $E$-matrices}

Lets define some notation: we define the \emph{transfer operator},
\begin{equation}
T(X) = \sum_s A^{s\dagger} X A^s
\end{equation}
which gives the spectrum of possible correlation functions, and is
a positive operator with all eigenvalues $\leq 1$. We assume here, for
simplicity, that there is only a single eigenvalue equal to 1.

Generalizing this transfer operator, we can let $K$ be an operator acting on
the local Hilbert space of the MPS, and define
\begin{equation}
T_K(X) = \sum_{s's} \bigbraket{s'}{K}{s} A^{s'\dagger} X A^s \; .
\end{equation}
Now we can express the $i^{\mathrm{th}}$ block operator $E_i[n]$ acting on
$n$ sites of the lattice, as
\begin{equation}
E_i[n] = T_{W_{ii}}(E_i[n-1]) + \sum_{j>i} T_{W_{ij}}(E_j[n-1]) \; .
\label{eq:MPORecurrence}
\end{equation}
The reason why we have split this into two terms, with the diagonal part $W_{ii}$
and the off-diagonal part $W_{ij}$, is that the $E_j$ matrices for $j>i$ are assumed to be
already calculated, so the off-diagonal part is some fixed matrix (actually
the matrices $E_j[n-1]$ will, in general, be a function of $n$, but as we will
see, this often presents no difficulty).

Let $C = \sum_{j>i} T_{W_{ij}}(E_j[n-1])$ be a constant matrix, and 
let $X = W_{ii}$ be the diagonal element of the MPO, that acts on the
local Hilbert space. Then 
\refeq{eq:MPORecurrence} reduces to
\begin{equation}
E_i[n] = T_{X}(E_i[n-1]) + C \; .
\label{eq:MPORecurrenceNicer}
\end{equation}

To start at obtaining the solution of this series, we can firstly
divide into two cases: (1) $C=0$. In this case, we have
\begin{equation}
E_i[n] = T_{X}(E_i[n-1]) \; ,
\end{equation}
which implies that $E_i$ is an eigenoperator of $T_X$ with eigenvalue 1. 
This is easily obtained.

Second case: $C \neq 0$. This is a generalized geometric series:
\begin{equation}
E_i[n] = C + T_X(C) + T^2_X{C} + \ldots + T^{n-1}_X(C) \; .
\end{equation}
To proceed further, we will make some further classifications of the MPO,
based on the properties of the diagonal local operator $X$. The first case
of interest (and the only one that is considered in this draft) is
the case where $X$ is a multiple of the identity operator, 
\begin{equation}
X = xI, \quad |x| \leq 1 \; ,
\end{equation}
and we further assume that $|x| \leq 1$ (this isn't a loss of generality, as we
can always change the normalization of the operator such that this is true).
Therefore, the generalized transfer operator $T_X$ reduces to a multiple of the
usual $T$, and we can choose a basis in which
$T$ is diagonal. Let the eigenvalues of $T$ be $\lambda_j$,
with corresponding eigenmatrices $P_j$.
Further, let the expansion coefficients of the fixed matrix $C$ in this basis
be $C = \sum_j c_j P_j$, and let us also expand the $E_i[n]$ in this basis,
as $E_i[n] = \sum_j e^j_i[n] P_j$.

The $E_i$ matrix is therefore given by
\begin{equation}
e^j_i[n] = x \lambda_j e^j_i[n-1] + c_j \; .
\end{equation}
This is an ordinary geometric series, with the $n$-th term being
\begin{equation}
e^j_i[n] = c_j \frac{1 - (x\lambda_j)^n}{1-x\lambda_j} \; ,
\label{eq:SeriesSolution}
\end{equation}
which is defined for $x \lambda_j \neq 1$.

We can therefore further subdivide into 3 cases;

(1) $x \lambda_j = 1$. This requires $x = 1$ (so that the diagonal
element of the MPO is the identity operator itself), and also $\lambda_j=1$, so
that we have the eigenvalue 1 of the transfer operator (corresponding
to the identity element). In this case,
the geometric series diverges, and we have
\begin{equation}
e^j_i[n] = n c_j \; ,
\end{equation}
which is the expectation value of a sum of local operators at every site,
where $n$ is the number of sites and $c_j$ is the expectation value per site.
This is an example where the $E[n]$-matrix is a function of $n$. Note however
that the $n$-dependence is just a constant times the identity operator (ie, the
eigenmatrix corresponding to the eigenvalue 1 of the transfer operator), so
this dependence is easy to account for. In general, this will result in
expectation values that are higher order polynomials of $n$.

(2) $|x \lambda_j| = 1$, but $x \neq 1$. The only way this case can occur is when
$\lambda_j = 1$, and $x$ is some c-number with $|x|=1$. Therefore, let
$x = e^{i\theta}$.  The $n$-th term of the geometric series is
\begin{equation}
e^j_i[n] =  c_j \frac{1 - e^{in\theta}}{1-e^{i\theta}} \; .
\end{equation}
Again, this is a function of $n$, but unlike the case (1) above, the series
does not diverge but is (quasi) periodic. 

(3) $|x \lambda_j| < 1$, where $x$ is a c-number. This case covers
the case of $|x| < 1$ (giving, for example, an MPO corresponding to
the sum of long-range but exponentially decaying terms), and also the
remaining eigenvalues $\lambda_j < 1$, when $|x|=1$.
In this case, the geometric series converges to a fixed point in the large $n$ limit,
giving
\begin{equation}
e^j_i = \frac{c_j}{1 - x\lambda_j} \; ,
\label{eq:EigenExpansion}
\end{equation}
which can be computed for all values of $j$ at once, using a linear solver.

\section{Higher order MPO's}

We have seen in the last section that the $E_i[n]$-matrices can, in some cases,
have a term that depends on $n$. For zero-momentum MPO's with identity operators
on the diagonal, this $n$-dependence is a simple linearly increasing term
that is proportional to the identity. For operators that have unitary factors
on the diagonal (eg, non-zero momentum), the $n$-dependence results in a quasi-periodic
structure. Therefore, 
the `constant' matrix $C$ in \refeq{eq:MPORecurrenceNicer} may actually be
a function of $n$. In principle, this can be handled easily because this
function is just a simple multiplier in the solution of the geometric series
(ie, the $c_j$ out the front of \refeq{eq:SeriesSolution}). This presents no problem
for cases (1) and (2) above, becuase here we are dealing with single eigenvalues
and we just need to keep track of the coefficient function of $n$. 

The remaining case is what happens in case (3), when the $c_j$ are arbitrary
(polynomial/perodic) functions of $n$. In the general case, if the $c_j$ all
became \emph{different} functions of $n$, then this case could be very difficult;
there may be no easier solution than diagonalizing completely the transfer operator
and constructing the eigenvector expansion \refeq{eq:EigenExpansion} directly.
But I hope (!) that many of the interesting MPO's result in the case where
the $c_j$ all have the \emph{same} dependence on $n$. That is, we have
\begin{equation}
c_j(n) = f(n) c^0_j \; .
\end{equation}
This case is readily treatable, since the solution $e^j_i[n]$ similarly
separates into $f(n)$ times a constant matrix.

\end{document}




